import uuid
from pathlib import Path
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
from pydantic import BaseModel
# from fastapi import status
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain_openai import OpenAI, ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders.text import TextLoader
from langchain_pinecone import PineconeVectorStore
from openai import OpenAI as OpenAIClient
from pinecone import Pinecone
import os
from chat import get_response
# from typing import List

app = Flask(__name__, template_folder='../chatbot.php')
CORS(app)

# Khá»Ÿi táº¡o FastAPI cho cÃ¡c loáº¡i dá»¯ liá»‡u
class AddText(BaseModel):
    text: str

class InputQuestion(BaseModel):
    question: str
    mode: str = 'medium'

class ParamsOpenAI(BaseModel):
    temperature: float = 0.7
    max_tokens: int = 800
    top_p: float = 0.95
    frequency_penalty: float = 0
    presence_penalty: float = 0
    stop_sequences: list | None = None
    system_content: str | None = None

# SYSTEM_MESSAGE_PROMPT_TEMPLATE = """Sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n ngá»¯ cáº£nh sau Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
# Má»™t sá»‘ quy táº¯c khi tráº£ lá»i cÃ¢u há»i:
# 1. NgÃ´n ngá»¯ Viá»‡t Nam Ä‘Æ°á»£c Æ°u tiÃªn.
# 2. Báº¡n nÃªn tráº£ lá»i "TÃ´i khÃ´ng biáº¿t" khi báº¡n khÃ´ng tháº¥y cÃ¢u tráº£ lá»i, khÃ´ng cá»‘ gáº¯ng táº¡o ra cÃ¢u tráº£ lá»i.
# 3. KhÃ´ng suy diá»…n cÃ¢u tráº£ lá»i, chá»‰ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ngá»¯ cáº£nh.
# 4. Tráº£ lá»i cÃ¢u há»i trong vÃ²ng dÆ°á»›i 150 tá»«.
# 5. KhÃ´ng Ä‘á» cáº­p Ä‘áº¿n cÃ¢u há»i trong cÃ¢u tráº£ lá»i.
# 6. Tráº£ lá»i cÃ¢u há»i báº±ng cÃ¹ng ngÃ´n ngá»¯ mÃ  cÃ¢u há»i Ä‘Æ°á»£c Ä‘áº·t ra.
# 7. CÃ¢u tráº£ lá»i cá»§a báº¡n nÃªn Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng dÆ°á»›i dáº¡ng markdown mÃ  khÃ´ng cáº§n ghi nháº­n Ä‘á»‹nh dáº¡ng.
# 8. Chá»‰ tráº£ lá»i trong pháº¡m vi kiáº¿n thá»©c dÆ°á»›i Ä‘Ã¢y.
# ----------------
# {context}"""

SYSTEM_MESSAGE_PROMPT_TEMPLATE = """Sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n ngá»¯ cáº£nh sau Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
Má»™t sá»‘ quy táº¯c khi tráº£ lá»i cÃ¢u há»i:
1. NgÃ´n ngá»¯ Viá»‡t Nam Ä‘Æ°á»£c Æ°u tiÃªn.
2. Báº¡n nÃªn tráº£ lá»i "Kiáº¿n thá»©c nÃ y khÃ´ng náº±m trong pháº¡m vi cá»§a tÃ´i" khi báº¡n khÃ´ng tháº¥y tá»« ngá»¯ nÃ o liÃªn quan Ä‘áº¿n ngá»¯ cáº£nh trong cÃ¢u há»i, khÃ´ng cá»‘ gáº¯ng táº¡o ra cÃ¢u tráº£ lá»i.
3. Chá»‰ tráº£ lá»i suy luáº­n dá»±a trÃªn ngá»¯ cáº£nh bÃªn dÆ°á»›i.
4. Tráº£ lá»i cÃ¢u há»i trong vÃ²ng dÆ°á»›i 150 tá»«.
5. KhÃ´ng Ä‘á» cáº­p Ä‘áº¿n cÃ¢u há»i trong cÃ¢u tráº£ lá»i.
6. Tráº£ lá»i cÃ¢u há»i báº±ng cÃ¹ng ngÃ´n ngá»¯ mÃ  cÃ¢u há»i Ä‘Æ°á»£c Ä‘áº·t ra.
7. CÃ¢u tráº£ lá»i cá»§a báº¡n nÃªn Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng dÆ°á»›i dáº¡ng markdown mÃ  khÃ´ng cáº§n ghi nháº­n Ä‘á»‹nh dáº¡ng vÃ  cÃ¢u tráº£ lá»i khÃ´ng cÃ³ cÃ¡c tiá»n tá»‘ Ä‘áº§u tiÃªn nhÆ° "Bot:", "Machine:", "System:".
8. Chá»‰ tráº£ lá»i trong pháº¡m vi kiáº¿n thá»©c dÆ°á»›i Ä‘Ã¢y.
----------------
{context}"""

# Thiáº¿t láº­p mÃ´i trÆ°á»ng

os.environ["OPENAI_API_KEY"] = ""
os.environ["OPENAI_ORGANIZATION"] = ""
os.environ["PINECONE_API_KEY"] = ""

pc = Pinecone(api_key="")
# Khá»Ÿi táº¡o Pinecone vÃ  cÃ¡c thÃ nh pháº§n Langchain
index = pc.Index("vectordb")

llm = OpenAI()
chat = ChatOpenAI(temperature=0.1)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key="")

@app.route('/')
def home():
    return render_template('chatbot.html')

@app.route('/get_response', methods=['POST'])
def handle_response():
    user_message = request.json['user_message']
    namespace = request.json.get('namespace', 'cosodulieu')
    response = get_response(user_message, namespace)
    print(response)
    return response

@app.route('/add_text', methods=['POST'])
def add_text():
    data = request.get_json()
    add_text_model = AddText(**data)
    id = uuid.uuid4().hex
    docs = [Document(page_content=add_text_model.text, metadata={'id': id, 'source': 'Data custom'}, ids=id)]
    PineconeVectorStore.from_documents(docs, embeddings, index_name="vectordb", ids=[id])
    return jsonify({"status": "success"})

@app.route('/add_data', methods=['GET'])
def add_data():
    db = PineconeVectorStore.from_existing_index(index_name="vectordb", embedding=embeddings)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[" ", ",", "\n"])
    loader = TextLoader(file_path="./cosodulieu/whole_text_chuanhoaldqh.txt", encoding='utf8')
    documents = loader.load()
    docs = text_splitter.split_documents(documents)
    db.add_documents(documents=docs, namespace="cosodulieu")
    return jsonify({"message": "Successfully!"})

@app.route('/init_data', methods=['GET'])
def init_data():
    db = PineconeVectorStore.from_existing_index(index_name="vectordb", embedding=embeddings, namespace="cosodulieu")
    db.delete(delete_all=True)
    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[" ", ",", "\n"])
    # loader = TextLoader(file_path="./whole_text/whole_text_dayso.txt", encoding='utf8')
    # documents = loader.load()
    # docs = text_splitter.split_documents(documents)
    # PineconeVectorStore.from_documents(docs, embeddings, index_name="vectordb")
    return jsonify({"message": "Succesfully"})

# @app.route('/get_namespace', methods=['GET'])
def compare_namespaces(question: str):
    # question = request.args.get('question')
    max_similarity = -1
    best_namespace = ""
    namespaces = index.describe_index_stats()['namespaces'].keys()
    print(namespaces)

    for namespace in namespaces:
        # Initialize PineconeVectorStore for each namespace

        # Search for similar documents in the namespace
        search_results = PineconeVectorStore(index_name="vectordb", embedding=embeddings, namespace=namespace).similarity_search_with_score(question, k=1)

        # Get the similarity score
        similarity_score = search_results[0][1] if search_results else 0
        print(similarity_score)

        # Compare similarity scores and update the best namespace
        if similarity_score > max_similarity:
            max_similarity = similarity_score
            best_namespace = namespace
        print(max_similarity)
    return best_namespace

def remove_prefix(text, prefixes):
    for prefix in prefixes:
        if text.startswith(prefix):
            print(f"Removing prefix: {prefix}")
            text = text[len(prefix):]
    return text


@app.route('/answer', methods=['POST'])
def chat_fun():
    data = request.get_json()
    input_data = InputQuestion(**data)
    documents = []
    best_namespace = ""

    if input_data.mode == 'medium':
        system_template = SYSTEM_MESSAGE_PROMPT_TEMPLATE
        messages = [
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template("{question}"),
        ]
        prompt = ChatPromptTemplate.from_messages(messages)
         # Compare namespaces based on input question
        if 'namespace' in data:
            best_namespace = data['namespace']
        else:
            best_namespace = compare_namespaces(input_data.question)
        print(best_namespace)
        data_search = PineconeVectorStore(index_name="vectordb", embedding=embeddings, namespace=best_namespace).similarity_search_with_score(input_data.question, k=4)
        context = ''
        len_list = len(data_search)
        index = 0
        for item in data_search:
            document = item[0]
            score = item[1]
            context += document.page_content
            if index < len_list - 1:
                context += "\n"
        chains = LLMChain(llm=OpenAI(temperature=0.1, max_tokens=900), prompt=prompt, verbose=True)
        data = chains.run({"context": context, "question": input_data.question})
        answer = data
    else:
        messages = [
            SystemMessage(content="You are a powerful assistant specializing in communication and answering questions."),
            HumanMessage(content=input_data.question),
        ]
        data = chat.invoke(messages)
        answer = data.content
    print(answer)
    answer = remove_prefix(answer, ["Machine:", "System:", "Bot:"])
    print("sau khi xá»­ lÃ­: ", answer)
    response_data = {
        "question": input_data.question,
        "answer": answer if answer != "" else "khÃ´ng thá»ƒ tráº£ lá»i",
        "namespace": best_namespace,
        "documents": documents,
    }
    return jsonify({
        'status': 1,
        'msg': "success",
        'data': response_data,
        'errors': []
    })

if __name__ == '__main__':
    app.run(debug=True)
    
    
    




# from flask import Flask, render_template, request
# from flask_cors import CORS
# from chat import get_response

# # app = Flask(__name__)
# app = Flask(__name__, template_folder='design')
# CORS(app)

# @app.route('/')
# def home():
#     return render_template('chatbot.html')

# @app.route('/get_response', methods=['POST'])
# def handle_response():  # Äá»•i tÃªn hÃ m xá»­ lÃ½ route thÃ nh handle_response
#     user_message = request.json['user_message']  # Sá»­ dá»¥ng request.json Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u
#     response = get_response(user_message)
#     print(response)
#     return response

# if __name__ == '__main__':
#     app.run(debug=True)





# import streamlit as st
# from chat import get_response

# # Äáº·t tiÃªu Ä‘á» má»›i cho á»©ng dá»¥ng Streamlit
# st.set_page_config(page_title="Chatbot")
# st.title("ðŸ¤–")

# # Khá»Ÿi táº¡o lá»‹ch sá»­ tin nháº¯n
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # Hiá»ƒn thá»‹ tin nháº¯n tá»« lá»‹ch sá»­ khi á»©ng dá»¥ng cháº¡y láº¡i
# for message in st.session_state.messages:
#     if message["role"] == "user":
#         with st.chat_message("user"):
#             st.markdown(message["content"])
#     else:
#         if "image" in message:
#             with st.expander("Image"):
#                 st.image(message["image"], use_column_width=True)
#         else:
#             with st.chat_message("assistant"):
#                 st.markdown(message["content"])

# # Nháº­n input tá»« ngÆ°á»i dÃ¹ng
# user_message = st.chat_input("Nháº­p tin nháº¯n cá»§a báº¡n:")
# if user_message:
#     # Hiá»ƒn thá»‹ tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
#     st.chat_message("user").markdown(user_message)
#     # ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ tin nháº¯n
#     st.session_state.messages.append({"role": "user", "content": user_message})

#     # Láº¥y pháº£n há»“i tá»« chatbot
#     response = get_response(user_message)
#     # print(response)

#     # Hiá»ƒn thá»‹ pháº£n há»“i cá»§a chatbot
#     if "image" in response and response["image"]:
#         with st.expander("Image"):
#             st.image(response["image"], use_column_width=True)
#     if "text" in response:  # Kiá»ƒm tra xem thuá»™c tÃ­nh text cÃ³ tá»“n táº¡i trong response hay khÃ´ng
#         st.chat_message("assistant").markdown(response["text"])
#     else:
#         st.chat_message("assistant").markdown(response)  # Náº¿u khÃ´ng cÃ³ text, hiá»ƒn thá»‹ response trá»±c tiáº¿p

#     # ThÃªm pháº£n há»“i cá»§a chatbot vÃ o lá»‹ch sá»­ tin nháº¯n
#     if "image" in response and response["image"]:
#         st.session_state.messages.append({"role": "assistant", "content": response.get("text", response), "image": response["image"]})
#     else:
#         st.session_state.messages.append({"role": "assistant", "content": response.get("text", response)})

